<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Random Thoughts on NeurIPS 2025 | Yoshinari Fujinuma (藤沼祥成)</title> <meta name="author" content="Yoshinari Fujinuma (藤沼祥成)"> <meta name="description" content="My impressions from attending NeurIPS 2025"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta property="og:site_name" content="Yoshinari Fujinuma (藤沼祥成)"> <meta property="og:type" content="website"> <meta property="og:title" content="Yoshinari Fujinuma (藤沼祥成) | Random Thoughts on NeurIPS 2025"> <meta property="og:url" content="https://akkikiki.github.io/blog/2025/neurips-2025-en/"> <meta property="og:description" content="My impressions from attending NeurIPS 2025"> <meta property="og:image" content="https://akkikiki.github.io/assets/img/neurips_registration_desk.jpg"> <meta property="og:locale" content="en"> <meta name="twitter:card" content="summary_large_image"> <meta name="twitter:title" content="Random Thoughts on NeurIPS 2025"> <meta name="twitter:description" content="My impressions from attending NeurIPS 2025"> <meta name="twitter:image" content="https://akkikiki.github.io/assets/img/neurips_registration_desk.jpg"> <meta name="twitter:site" content="@akkikiki"> <meta name="twitter:creator" content="@akkikiki"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://akkikiki.github.io/blog/2025/neurips-2025-en/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Yoshinari </span>Fujinuma (藤沼祥成)</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/notes/">misc</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Random Thoughts on NeurIPS 2025</h1> <p class="post-meta">December 7, 2025</p> <p class="post-tags"> <a href="/blog/2025"> <i class="fas fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/conference"> <i class="fas fa-hashtag fa-sm"></i> conference</a>   <a href="/blog/tag/english"> <i class="fas fa-hashtag fa-sm"></i> English</a>     ·   <a href="/blog/category/life"> <i class="fas fa-tag fa-sm"></i> Life</a>   </p> </header> <article class="post-content"> <div id="table-of-contents"> <ul id="toc" class="section-nav"> <li class="toc-entry toc-h2"><a href="#introduction">Introduction</a></li> <li class="toc-entry toc-h2"><a href="#conference-reflections-learnings-and-takeaways">Conference Reflections, Learnings, and Takeaways</a></li> <li class="toc-entry toc-h2"><a href="#final-remark">Final Remark</a></li> </ul> </div> <hr> <div id="markdown-content"> <h2 id="introduction">Introduction</h2> <figure style="text-align: center;"> <img src="/assets/img/neurips_venue.jpg" alt="NeurIPS Venue" width="75%" style="filter: brightness(0.9);"> <figcaption>A bird's-eye view of the NeurIPS 2025 venue from outside. You can see the sign for Venue "F" in the middle of the building, but there are venues all the way to "A" (not visible in this image), making this an extremely large venue</figcaption> </figure> <ol> <li>General impressions: <ol> <li>People, People, and People! Nearly 30,000 participants including virtual and in-person attendance.</li> <li>At a conference of tens of thousands of people, encountering someone you know by chance becomes nearly miraculous, so scheduling 1:1 meetings in advance or during the conference was extremely beneficial. Also, even as a graduate student who isn’t famous, people were surprisingly willing to listen to my talks and questions.</li> <li>Please note that I only saw or heard about roughly 50 presentations, i.e., 50/5833 ~= 0.0086 = 0.86% of the entire conference, so my impressions might be completely different from others’ (I’d love to hear others’ impressions). Also, since I come from a language processing/NLP background, I only skimmed through image and video-related posters and presentations.</li> </ol> </li> </ol> <figure style="text-align: center;"> <img src="/assets/img/neurips_stats.png" alt="NeurIPS stats" width="75%" style="filter: brightness(0.9);"> <figcaption>NeurIPS 2025 statistics</figcaption> </figure> <h2 id="conference-reflections-learnings-and-takeaways">Conference Reflections, Learnings, and Takeaways</h2> <ol> <li>Setting up 1:1 meetings <ol> <li>At *ACL conferences I attended until 2023, I didn’t set up 1:1 meetings, but I remembered someone I previously worked with doing this at NAACL 2022. With nearly 30,000 participants (virtual and in-person), I thought it would definitely be worthwhile this time and put it into practice.</li> <li>Searching for #NeurIPS2025 on Twitter/X, I found quite a few participants posting “feel free to reach out,” so I set up meetings within my capacity.</li> <li>The conversations I had during these 1:1s were actually the most interesting and informative part of the conference, even more than the presentations.</li> </ol> </li> <li>The abundance of VC and corporate sponsor events <ol> <li>I remember after-parties hosted by sponsors at ACL 2019, but the sheer number at NeurIPS was on a different scale. <ol> <li>The most comprehensive list is in <a href="https://kittyinthewild.substack.com/p/neurips-2025-social-and-event-tracking" rel="external nofollow noopener" target="_blank">this substack post</a>.</li> </ol> </li> <li>Actually, my motivation for attending came from seeing <a href="https://x.com/jungokasai/status/1736053133221019885" rel="external nofollow noopener" target="_blank">Jungo Kasai’s tweet</a> about two years ago and speaking with him directly. I became curious about “how different is this from *ACL conferences?” and decided to attend this year out of curiosity (I was too busy with job hunting last year to make it). <ol> <li>Having actually attended in person, as you can see from the number of sponsor after-parties, the atmosphere is quite different.</li> <li>The corporate booths had neon company logos glowing and moving, giving the overall impression of “a lot of money has been spent here.”</li> </ol> </li> </ol> </li> </ol> <figure style="text-align: center;"> <img src="/assets/img/neurips_sponsor_booth.jpg" alt="NeurIPS Sponsor Booth" width="75%" style="filter: brightness(0.9);"> <figcaption>Corporate sponsor booths at the venue</figcaption> </figure> <ol> <li>Simultaneous presentations of the diffusion language model <a href="https://arxiv.org/abs/2502.09992" rel="external nofollow noopener" target="_blank">LLaDA 8B</a> and research using it <ol> <li>At NeurIPS, there were many presentations on how to accelerate diffusion language models. For details, see the papers on NeurIPS’s <a href="https://scholar-inbox.com/conference/neurips/2025" rel="external nofollow noopener" target="_blank">Scholar Inbox</a>, so I’ll omit the details here.</li> <li>This is my personal impression, but it reminded me of NAACL 2019 when BERT was presented, but it had already been buzzing since the arXiv/Github debut in 2018, so BERT itself, its analysis, and papers using BERT were all presented at the same conference. Déjà vu. <ol> <li>On a side note, the history of language models is: n-gram language models → (solving other NLP tasks with SVM/CRF/LDA, etc.) → word2vec/RNN → LSTM → BERT (this one) → GPT-1/2/3 → ChatGPT/GPT-3.5 → … and more to come for diffusion language models!</li> </ol> </li> <li>On NeurIPS’s <a href="https://scholar-inbox.com/conference/neurips/2025" rel="external nofollow noopener" target="_blank">Scholar Inbox</a>, you can see the number of likes, and LLaDA 8B had over 100 likes, giving the impression of being quite popular (incidentally, there was such a crowd at the poster session that I gave up and went to listen to other posters).</li> <li>I requested several 1:1 meetings, and the most interesting paper is the <a href="https://arxiv.org/pdf/2506.10892" rel="external nofollow noopener" target="_blank">paper on Uniform State Diffusion Model</a> (not from NeurIPS though) which was introduced to me during one of them. <ol> <li>Since Prof. Chris Manning’s invited talk at EMNLP 2023 covered Direct Preference Optimization, which was to be presented at NeurIPS 2023, I realized once again that recent conferences are becoming places to hear about content that will be presented at the next conference.</li> </ol> </li> </ol> </li> </ol> <figure style="text-align: center;"> <img src="/assets/img/masked_vs_uniform_state_diffusion_lm.png" alt="Masked vs Uniform State Diffusion Language Model" width="75%"> <figcaption>Comparison of Masked Diffusion and Uniform State Diffusion language models. (this figure is very intuitive as a person with an NLP background :)) Cited from <a href="https://arxiv.org/pdf/2506.10892" rel="external nofollow noopener" target="_blank">The Diffusion Duality</a> (CC BY 4.0) </figcaption> </figure> <ol> <li>Uniform State Diffusion Language Model <ol> <li>LLaDA and <a href="https://hkunlp.github.io/blog/2025/dream/" rel="external nofollow noopener" target="_blank">Dream</a> are the most buzzed diffusion language models I know of, but they are masked diffusion (i.e., the initial state when generating a sentence is all [MASK] tokens), whereas Uniform-state diffusion has an initial sentence state that is randomly sampled from the model’s vocabulary.</li> <li>I asked questions and received explanations directly from the author during a 1:1 meeting. Having it explained directly was indeed much clearer in terms of which parts of the paper to focus on, the order (not left-to-right but quite random order, same as the inference of diffusion language models), and behind-the-scenes stories. (Not disclosing here just in case since this is non-public.)</li> <li>Uniform-State Diffusion naturally models re-masking (the method of replacing tokens that have once transitioned from [MASK] tokens to non-mask tokens back to [MASK] tokens again, although it does not use [MASK] tokens to begin with). <ol> <li> <a href="https://arxiv.org/pdf/2503.00307" rel="external nofollow noopener" target="_blank">ReMDM</a>, which was also presented at NeurIPS 2025, is exactly about this remasking.</li> <li>(At this point I understood why masked diffusion models are called absorbing state diffusion. Like a black hole, they are absorbed into the [MASK] token, and because the assumption is that they don’t transition from that state, they are called absorbing state diffusion.)</li> </ol> </li> <li>By the way, not directly related to the conference, but <a href="https://prednext.com/blog/diffusion-language-model-2/" rel="external nofollow noopener" target="_blank">Between Diffusion Language Models and Autoregressive Models (In Japanese)</a> written by Tokunaga-san was also interesting. My personal impression is that uniform-state diffusion is one of the continuations of this blog. <ol> <li>I discussed with participants on-site whether diffusion language models will fully replace autoregressive models and become mainstream, and opinions were quite divided. My personal opinion is that current diffusion language models are at the stage of autoregressive models from a few years ago (specifically, the era when Llama 1 training was still unstable, or BERT, which isn’t an autoregressive model but as I mentioned above). So I predict that over the next few years, many open-weight models and inference engines will be developed (e.g., <a href="https://github.com/sgl-project/sglang/issues/12766" rel="external nofollow noopener" target="_blank">SGLang is in full steam</a> and other inference engines will likely follow), and they will be introduced in earnest from 2026 onwards as agents in fields where diffusion language models’ properties are compatible, such as protein design where sequence length is fixed, program generation where repetition is common and multiple tokens are more predictable than natural language, and many other fields!</li> </ol> </li> </ol> </li> <li>Model Merge-related topics <ol> <li>The tutorial on Model Merge on Day 1 left an impression. The first half seemed similar to what I saw in <a href="https://cameronrwolfe.substack.com/p/model-merging" rel="external nofollow noopener" target="_blank">Model Merging: A Survey</a>.</li> <li>What was most educational for me was the merging of Mixture of Expert (MoE) models. Naming MoE merging “MoErging” in the tutorial was somehow a “clever” naming choice. It actually stuck in my head even though I heard it on Day 1 (although the forgetting curve was reset because I attended one MoErging poster during the conference). <ol> <li>The impression was that they were breaking down <a href="https://arxiv.org/abs/2408.07057" rel="external nofollow noopener" target="_blank">A Survey on Model MoErging: Recycling and Routing Among Specialized Experts for Collaborative Learning</a>.</li> </ol> </li> </ol> </li> <li>Other/Misc <ol> <li>When I attended WWW2016 as an auditor in the past, there weren’t many language processing presentations and I didn’t know many people, so it wasn’t that interesting for me back in that time, but this year’s NeurIPS was very interesting for me. Especially since LLMs are now incorporated as modules regardless of whether they’re for images, audio, or video, there were hardly any irrelevant presentations.</li> </ol> </li> </ol> <h2 id="final-remark">Final Remark</h2> <p>Thank you to everyone who met, talked, and discussed with me on-site.</p> <p>Also, big thank you to the attendants and presenters who tried their best to speak English even if it’s not their first language during the poster presentations. Very much appreciated. I also did my best not to speak Japanese during poster presentations.</p> <p>Finally, if you are looking for someone to collaborate with, don’t hesitate to contact me at fujinumay at gmail dot com!</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/neurips-2025/">NeurIPS 2025の感想</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/Green-Card-Timeline/">レイオフ時代におけるグリーンカード取得体験記（EB1B/EB2-NIW編）</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/PhD-life/">PhD Retrospective Part 1</a> </li> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Yoshinari Fujinuma (藤沼祥成). Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js"></script> <script defer src="/assets/js/common.js"></script> <script defer src="/assets/js/copy_code.js" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>