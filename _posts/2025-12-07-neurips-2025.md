---
layout: post
title: NeurIPS 2025の感想
date: 2025-12-07 15:09:00
description: NeurIPSに行った感想
tags: conference 日本語
categories: Life
featured: false
og_image: https://akkikiki.github.io/assets/img/green_card_received.jpg
toc:
  beginning: true
---

## はじめに

<img src="/assets/img/neurips_stats.png" alt="NeurIPS stats" width="75%" style="filter: brightness(0.7);">

Virtualと現地含めて3万人近く。

自分が見聞きしたのはせいぜい50件、50/5833 ~= 0.0086 =  0.86% と会議全体の非常に小さな部分しか見聞きできていないので、他の方々の印象とは180度違う可能性があるのでご留意ください。（ぜひ他の方々の感想も見聞きしたいです）。あと自分は言語処理・NLP系出身なので、全体的に画像・ビデオ部分のポスター・発表は流し見だけしかしていません。

1. TL; DR (Too Long Don’t Read):
    1. めちゃくちゃ人がいた。Virtualと現地含めて3万人近くらしい。
    2. 数万人規模の会議になると偶然知り合いに遭遇するのは奇跡的な確率になるので1:1を事前もしくは会議中にお願いしたのは非常に良かった。あと自分みたいな学生でも有名でもない人の話・質問でも意外と聞いてくれた。
2. 1:1の設定
    1. 実は2023年までの*ACL系の会議では特に1:1は設定していなかったが、元CMUの大谷さんがNAACL2022でやっていられるのを覚えていて、Virtualと現地含めて3万人近くの参加者のため、さすがに今回はやった方が良いと思い実践した。
    2. 旧ツイッター上#NeurIPS2025で検索すると結構「声かけてねー」とあったので、自分のキャパを超えない程度に設定。
    3. 実は発表よりここで聞いた話が一番面白くて参考になった印象。
3. VC・企業スポンサーイベントの多さ
    1. 確か2022年ACLでもスポンサーのアフターパーティが開催されていたのは覚えているのですが、とにかく数が違う。
        1. 一番網羅的なのは[こちら](https://kittyinthewild.substack.com/p/neurips-2025-social-and-event-tracking)
    2. 実は動機としては二年程前に[笠井さんのツイート](https://x.com/jungokasai/status/1736053133221019885)を拝見し、直接話も聞いて「どれだけ*ACL系の会議と違うのだろう」という興味本位で今回行ったのがきっかけ（昨年は転職活動で忙しかったため叶わず）
        1. 実際現地に行ってみると、スポンサーのアフターパーティから見てもわかる通り、かなり雰囲気が違う。
        2. 企業ブースも企業ロゴのネオンやらが輝いていたり、動いていたり、とにかく「お金がかかっているなー」という印象。
4. 拡散言語モデルであるLLaDA 8Bとそれを使った研究が同時に発表
    1. 個人的な感想ですが、2019年NAACLでBERT（言語モデルの大まかな流れはn-gram言語モデル→ RNN→ LSTM/word2vec→BERT(コレ)→GPT-1/2/3→ ChatGPT/GPT-3.5 → …）が発表されたが、2018年時点で既にバズっていたのでBERT自体の発表とその解析自体が同じ会議で発表されたのを思い出した。
    2. NeurIPSの[Scholar Inbox](https://scholar-inbox.com/conference/neurips/2025)ではいいね数もみれるのですが、LLaDA 8Bは100以上いいねがついていてやはり人気な印象でした（ちなみにポスターセッションは人垣ができていたので諦めて他のポスターを聞いて回ってました。）
    3. MDLMの第一著者であるSubham Sahoo博士との1:1で紹介して頂いたご自身の最新論文であるUniform State Diffusion Modelに関する論文が（NeurIPSではない?）が一番面白かった。
5. LLaDAやDreamが自分が知っている中でバズったモデルですが、それらはmasked diffusion (i.e., 文を生成する時の初期状態が[MASK]トークン)でありUniform-state diffusionは文の初期状態がモデルのvocabularyからランダムにサンプリングされたもの。
    1. （やはり著者が直接説明して頂いた方がどこに注目するべきか、裏話なども聞けて非常にわかりやすかった)
    2. Uniform-State Diffusionだとre-masking（一度[MASK]トークンからそうでないものに遷移したトークンをもう一度[MASK]トークンに置換する方法）が自然にモデル化されている
        1. NeurIPS 2025でも発表されたReMDMとかがまさしくこのremaskingに関すること
        2. （この時点でmasked diffusion modelがなぜabsorbing state diffusionと呼ばれるか理解した。ブラックホールのように[MASK]トークンに吸収されるイメージで、その状態から遷移しないことが前提のためabsorbing state diffusionと呼ばれる）
    3. ちなみに会議と関係ありませんが拡散言語モデルに関しては[こちら](https://prednext.com/blog/diffusion-language-model-2/)も面白かったです。uniform-state diffusionがこちらのパート2の次のパート、というのが勝手なイメージです。

<img src="/assets/img/masked_vs_uniform_state_diffusion_lm.png" alt="Masked vs Uniform State Diffusion Language Model" width="75%">

1. Model Merge関連
    1. Model Mergeはかなりお世話になっていたが、チュートリアルの前半部分は[こちら](https://cameronrwolfe.substack.com/p/model-merging)の詳細を省いたものに近い印象。
    2. ただ、自分にとって新しい部分は混合エキスパートモデル（Mixture of Expert, MoE）のマージ。チュートリアルでMoEのマージをMoErgingという名前をつけているのが、何というか「上手い」名付けという印象。実際１日目に聞いたにも関わらず自分の頭にも残っている（ただ、会議中に一つMoErgingのポスターを聞いたため忘却曲線がリセットされている）
        1. [こちら](https://arxiv.org/abs/2408.07057)を噛み砕いて話していた印象
2. その他・Misc
    1. 昔WWW2016に聴講に行った時はあまり言語処理系の発表がなく、知り合いもあまりいなかったため、あまり面白くなかったが、NeurIPSは個人的には面白かった。特にLLMはもう画像、音声、ビデオ問わず、モジュールの一つとして組みこまれているので、関係ない発表があまりない。

## **お仕事・共同研究募集中です**

2025年7月に米国永住権であるグリーンカードを取得したため、ようやくビザの制約から解放されてフリーでも仕事を探し中です。ご興味のある方はfujinumay at gmail dot comまでお待ちしております。

本記事のライセンス: [CC-BY-NC-SA-4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) （商用目的での利用を禁止）
